{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf149a0-2504-46a6-9856-eb2943d62a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88dd92b-7666-4a50-ac9c-77e67860faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6128d5b9-a172-4e7e-9f51-51f519d3259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Scrape the Webpage\n",
    "url = 'https://en.wikipedia.org/wiki/Hanford_Engineer_Works'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66351544-7cbf-4d16-932d-ca3b1259f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    text_content = soup.get_text()\n",
    "else:\n",
    "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "    text_content = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "371405ea-01e6-4a5e-a518-df986bc2f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define Chunking Methods\n",
    "def fixed_length_chunking(text, chunk_size):\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "def semantic_chunking(text, start):\n",
    "    adjusted_text = text[start:]\n",
    "    paragraphs = adjusted_text.split('\\n\\n')\n",
    "    return paragraphs\n",
    "\n",
    "def overlapping_chunking(text, chunk_size, overlap):\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size - overlap)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a461a9f1-453b-4c4c-8584-850284bfd12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function to calculate coherence using sentence boundaries\n",
    "def calculate_sentence_boundary_coherence(chunk):\n",
    "    return chunk.count('.') + chunk.count('!') + chunk.count('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f8c4d59-e454-49d2-b6aa-7790a6fe29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Experiment with Different Chunk Sizes and Methods\n",
    "chunk_sizes = [256, 512, 1024, 2048]\n",
    "overlap = 50  # Example overlap for overlapping chunking\n",
    "start_position = 5000  # Example start position for semantic chunking\n",
    "\n",
    "chunking_methods = {\n",
    "    'Fixed-Length': fixed_length_chunking,\n",
    "    'Semantic': lambda text, size: semantic_chunking(text, start_position),\n",
    "    'Overlapping': overlapping_chunking\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for method_name, chunking_function in chunking_methods.items():\n",
    "    results[method_name] = {}\n",
    "    for size in chunk_sizes:\n",
    "        if method_name == 'Fixed-Length':\n",
    "            chunks = chunking_function(text_content, size)\n",
    "        elif method_name == 'Overlapping':\n",
    "            chunks = chunking_function(text_content, size, overlap)\n",
    "        elif method_name == 'Semantic':\n",
    "            chunks = chunking_function(text_content, start_position)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Perform the task on each chunk and collect metrics\n",
    "        coherence_scores = [calculate_sentence_boundary_coherence(chunk) for chunk in chunks]\n",
    "        \n",
    "        end_time = time.time()\n",
    "        processing_time = (end_time - start_time) * 1000 \n",
    "        \n",
    "        # Store the results\n",
    "        results[method_name][size] = {\n",
    "            'num_chunks': len(chunks),\n",
    "            'total_coherence': sum(coherence_scores),\n",
    "            'avg_coherence': sum(coherence_scores) / len(coherence_scores) if chunks else 0,\n",
    "            'processing_time': processing_time\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "689eb5c2-b36c-44c3-9045-6e1db1d4ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking Method: Fixed-Length\n",
      "  Chunk Size: 256\n",
      "    Number of Chunks: 372\n",
      "    Total Coherence: 1478\n",
      "    Average Coherence: 3.97\n",
      "    Processing Time: 0.58 ms\n",
      "  Chunk Size: 512\n",
      "    Number of Chunks: 186\n",
      "    Total Coherence: 1478\n",
      "    Average Coherence: 7.95\n",
      "    Processing Time: 0.45 ms\n",
      "  Chunk Size: 1024\n",
      "    Number of Chunks: 93\n",
      "    Total Coherence: 1478\n",
      "    Average Coherence: 15.89\n",
      "    Processing Time: 0.35 ms\n",
      "  Chunk Size: 2048\n",
      "    Number of Chunks: 47\n",
      "    Total Coherence: 1478\n",
      "    Average Coherence: 31.45\n",
      "    Processing Time: 0.29 ms\n",
      "\n",
      "\n",
      "Chunking Method: Semantic\n",
      "  Chunk Size: 256\n",
      "    Number of Chunks: 290\n",
      "    Total Coherence: 1440\n",
      "    Average Coherence: 4.97\n",
      "    Processing Time: 0.52 ms\n",
      "  Chunk Size: 512\n",
      "    Number of Chunks: 290\n",
      "    Total Coherence: 1440\n",
      "    Average Coherence: 4.97\n",
      "    Processing Time: 0.32 ms\n",
      "  Chunk Size: 1024\n",
      "    Number of Chunks: 290\n",
      "    Total Coherence: 1440\n",
      "    Average Coherence: 4.97\n",
      "    Processing Time: 0.25 ms\n",
      "  Chunk Size: 2048\n",
      "    Number of Chunks: 290\n",
      "    Total Coherence: 1440\n",
      "    Average Coherence: 4.97\n",
      "    Processing Time: 0.33 ms\n",
      "\n",
      "\n",
      "Chunking Method: Overlapping\n",
      "  Chunk Size: 256\n",
      "    Number of Chunks: 462\n",
      "    Total Coherence: 1830\n",
      "    Average Coherence: 3.96\n",
      "    Processing Time: 0.38 ms\n",
      "  Chunk Size: 512\n",
      "    Number of Chunks: 206\n",
      "    Total Coherence: 1660\n",
      "    Average Coherence: 8.06\n",
      "    Processing Time: 0.24 ms\n",
      "  Chunk Size: 1024\n",
      "    Number of Chunks: 98\n",
      "    Total Coherence: 1545\n",
      "    Average Coherence: 15.77\n",
      "    Processing Time: 0.19 ms\n",
      "  Chunk Size: 2048\n",
      "    Number of Chunks: 48\n",
      "    Total Coherence: 1506\n",
      "    Average Coherence: 31.38\n",
      "    Processing Time: 0.17 ms\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Evaluate Results\n",
    "for method_name, method_results in results.items():\n",
    "    print(f\"Chunking Method: {method_name}\")\n",
    "    for size, metrics in method_results.items():\n",
    "        print(f\"  Chunk Size: {size}\")\n",
    "        print(f\"    Number of Chunks: {metrics['num_chunks']}\")\n",
    "        print(f\"    Total Coherence: {metrics['total_coherence']}\")\n",
    "        print(f\"    Average Coherence: {metrics['avg_coherence']:.2f}\")\n",
    "        print(f\"    Processing Time: {metrics['processing_time']:.2f} ms\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef5745-1d88-445e-8d5d-1b876d634222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
